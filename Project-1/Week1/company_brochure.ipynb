{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "278e103b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# import sys\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# from pathlib import Path\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# sys.path.append(str(Path.cwd().parent))\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# from utils.scrapper import fetch_website_contents, fetch_website_links\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m     11\u001b[39m runLocalModels=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Markdown, display, update_display\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "# sys.path.append(str(Path.cwd().parent))\n",
    "# from utils.scrapper import fetch_website_contents, fetch_website_links\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "runLocalModels=False\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75bda7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_from_website(url):\n",
    "    response = requests.get(url)\n",
    "    content = BeautifulSoup(response.content,\"html.parser\")\n",
    "    links= [link.get(\"href\") for link in content.find_all(\"a\")]\n",
    "    valid_links = list(filter(lambda x: x.startswith(\"http\"), links))\n",
    "    return valid_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f800109d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api key exists\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key and api_key.startswith(\"sk-proj\") and len(api_key)>10 :\n",
    "    print(\"api key exists\")\n",
    "else:\n",
    "    print(\"no api key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9a06570",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"\"\"you are provided with list of urls found in a web page\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company,\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
    "You should respond in JSON as in this example:\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22df0715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt(url):\n",
    "    user_prompt = f\"\"\"Here is the list of urls found on the website (blog) {url}\n",
    "    Please decide which of these are relevant web links for a brochure about the company, \n",
    "    respond with the full https URL in JSON format.\n",
    "    Do not include Terms of Service, Privacy, email links.\n",
    "\n",
    "    Links (some might be relative links):\n",
    "    \"\"\"\n",
    "    links=get_links_from_website(url)\n",
    "    user_prompt+=\"\\n\".join(links)\n",
    "    return user_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e2f9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ai_instance():\n",
    "    if requests.get(\"http://localhost:11434\").ok and runLocalModels:\n",
    "        MODEL =\"gpt-oss:20b\"\n",
    "        OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "        ai_instance = OpenAI(base_url=OLLAMA_BASE_URL,api_key=\"ollama\")\n",
    "    else:\n",
    "        MODEL=\"gpt-5-nano\"\n",
    "        ai_instance = OpenAI()\n",
    "    return (ai_instance,MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "814a46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ai_to_get_relavent_links(url,ai,model):\n",
    "    print(f\"Selecting relevant links for {url} by calling {model} on local mode {runLocalModels}\")\n",
    "    response = ai.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\" : \"system\",\"content\": link_system_prompt},\n",
    "             {\"role\" : \"user\" , \"content\" : get_user_prompt(url)}],\n",
    "    response_format={\"type\" : \"json_object\"})\n",
    "    result= response.choices[0].message.content\n",
    "    links = json.loads(result)\n",
    "    print(f\"found {len(links['links'])} relevant links\")\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3bd0372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting relevant links for https://huggingface.co/ by calling gpt-5-nano on local mode False\n",
      "found 5 relevant links\n"
     ]
    }
   ],
   "source": [
    "links = call_ai_to_get_relavent_links(\"https://huggingface.co/\",get_ai_instance()[0],get_ai_instance()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a8fbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = scrapper.fetch_website_contents(\"https://huggingface.co/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e7664d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_website_and_contents(url):\n",
    "    contents = scrapper.fetch_website_contents(url)\n",
    "    relevant_links = links\n",
    "    result = f\"## Landing Page:\\n\\n{contents}\\n## Relevant Links:\\n\"\n",
    "    for link in relevant_links['links']:\n",
    "        result += f\"\\n\\n###{link['type']}\\n\"\n",
    "        result += scrapper.fetch_website_contents(link['url'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4158cc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Landing Page:\n",
      "\n",
      "Hugging Face ‚Äì The AI community building the future.\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "microsoft/VibeVoice-Realtime-0.5B\n",
      "Updated\n",
      "1 day ago\n",
      "‚Ä¢\n",
      "67.7k\n",
      "‚Ä¢\n",
      "626\n",
      "Tongyi-MAI/Z-Image-Turbo\n",
      "Updated\n",
      "2 days ago\n",
      "‚Ä¢\n",
      "233k\n",
      "‚Ä¢\n",
      "2.46k\n",
      "zai-org/GLM-4.6V-Flash\n",
      "Updated\n",
      "about 18 hours ago\n",
      "‚Ä¢\n",
      "10k\n",
      "‚Ä¢\n",
      "276\n",
      "zai-org/GLM-4.6V\n",
      "Updated\n",
      "1 day ago\n",
      "‚Ä¢\n",
      "1.31k\n",
      "‚Ä¢\n",
      "233\n",
      "deepseek-ai/DeepSeek-V3.2\n",
      "Updated\n",
      "9 days ago\n",
      "‚Ä¢\n",
      "40.7k\n",
      "‚Ä¢\n",
      "852\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "Featured\n",
      "1.29k\n",
      "Z Image Turbo\n",
      "üèÉ\n",
      "1.29k\n",
      "Generate images from text prompts\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "458\n",
      "Z Image Turbo\n",
      "üñº\n",
      "458\n",
      "Generate stunning images from text prompts\n",
      "Running\n",
      "170\n",
      "Evaluation Guidebook\n",
      "üìù\n",
      "170\n",
      "Display evaluation metrics for LLM benchmarks\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "Featured\n",
      "883\n",
      "Dream-wan2-2-faster-Pro\n",
      "üé¨\n",
      "883\n",
      "Generate videos from images using prompts\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "Featured\n",
      "467\n",
      "FLUX.2 [dev]\n",
      "üíª\n",
      "467\n",
      "Generate detailed images from text or edit existing images\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "Anthropic/AnthropicInterviewer\n",
      "Updated\n",
      "1 day ago\n",
      "‚Ä¢\n",
      "6.19k\n",
      "‚Ä¢\n",
      "188\n",
      "TuringEnterprises/Turing-Open-Reasoning\n",
      "Updated\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "4.69k\n",
      "‚Ä¢\n",
      "59\n",
      "nvidia/ToolScale\n",
      "Updated\n",
      "13 days ago\n",
      "‚Ä¢\n",
      "2.31k\n",
      "‚Ä¢\n",
      "99\n",
      "nvidia/PhysicalAI-Autonomous-Vehicles\n",
      "Updated\n",
      "5 days ago\n",
      "‚Ä¢\n",
      "178k\n",
      "‚Ä¢\n",
      "483\n",
      "openai/gdpval\n",
      "Updated\n",
      "Sep 25\n",
      "‚Ä¢\n",
      "24.7k\n",
      "‚Ä¢\n",
      "321\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Team & Enterprise\n",
      "Give your team the most advanced platform to build A\n",
      "## Relevant Links:\n",
      "\n",
      "\n",
      "###product page\n",
      "Inference Endpoints by Hugging Face\n",
      "\n",
      "Inference\n",
      "Endpoints\n",
      "Catalog\n",
      "Log In\n",
      "Machine Learning At Your Service\n",
      "by\n",
      "Hugging Face\n",
      "Easily deploy your AI models to production on our fully managed platform. Instead of\n",
      "\t\t\t\tspending weeks configuring infrastructure, focus on building you AI application.\n",
      "Log In\n",
      "Learn More\n",
      "No Hugging Face account ?\n",
      "Sign up\n",
      "!\n",
      "One-click deployment\n",
      "Import your favorite model from Hugging Face or browse our catalog of hand-picked, ready-to-deploy models!\n",
      "ibm-granite /\n",
      "granite-3.3-8b-instruct-FP8\n",
      "10\n",
      "Deployed 10 times\n",
      "Text Generation\n",
      "vLLM\n",
      "Accelerated vLLM\n",
      "GPU\n",
      "1x Nvidia L40S\n",
      "$\n",
      "1.8\n",
      "openai /\n",
      "gpt-oss-safeguard-20b\n",
      "23\n",
      "Deployed 23 times\n",
      "Text Generation\n",
      "vLLM\n",
      "Accelerated vLLM\n",
      "GPU\n",
      "1x Nvidia L40S\n",
      "$\n",
      "1.8\n",
      "allenai /\n",
      "olmOCR-2-7B-1025-FP8\n",
      "30\n",
      "Deployed 30 times\n",
      "Image-Text-to-Text\n",
      "vLLM\n",
      "Accelerated vLLM\n",
      "GPU\n",
      "1x Nvidia L40S\n",
      "$\n",
      "1.8\n",
      "Qwen /\n",
      "Qwen3-VL-30B-A3B-Thinking\n",
      "22\n",
      "Deployed 22 times\n",
      "Image-Text-to-Text\n",
      "vLLM\n",
      "Accelerated vLLM\n",
      "GPU\n",
      "2x Nvidia A100\n",
      "$\n",
      "5\n",
      "Qwen /\n",
      "Qwen3-VL-8B-Instruct\n",
      "69\n",
      "Deployed 69 times\n",
      "Image-Text-to-Text\n",
      "vLLM\n",
      "Accelerated vLLM\n",
      "GPU\n",
      "1x Nvidia A100\n",
      "$\n",
      "2.5\n",
      "Browse Catalog\n",
      "Hub Models\n",
      "Trusted By\n",
      "These teams are running AI models on Inference Endpoints\n",
      "Features\n",
      "Everything you need to deploy AI models at scale\n",
      "Fully Managed Infrastructure\n",
      "Don't worry about Kubernetes, CUDA versions, or configuring VPNs. Focus on deploying your model and serving customers.\n",
      "Autoscaling\n",
      "Automatically scales up as traffic increases and down as it decreases to save on compute costs.\n",
      "Observability\n",
      "Understand and debug your model through comprehensive logs & metrics.\n",
      "Inference Engines\n",
      "Deploy with vLLM, TGI, SGLang, TEI, or custom containers.\n",
      "Hugging Face Integration\n",
      "Download model weights fast and securely with seamless Hugging Face Hub integration.\n",
      "Future-proof AI Stack\n",
      "Stay current with the latest frameworks and optimizations without managing complex upgrades.\n",
      "Pricing\n",
      "Choose a plan that fits your needs\n",
      "Self-Serve\n",
      "Pay as you go when using Inference Endpoints\n",
      "Pay for what you use, per minute\n",
      "Starting a\n",
      "\n",
      "###careers page\n",
      "Hugging Face - Current Openings\n",
      "\n",
      "\n",
      "\n",
      "###company page\n",
      "Hugging Face | LinkedIn\n",
      "\n",
      "Skip to main content\n",
      "LinkedIn\n",
      "Top Content\n",
      "People\n",
      "Learning\n",
      "Jobs\n",
      "Games\n",
      "Get the app\n",
      "Sign in\n",
      "Join now for free\n",
      "Hugging Face\n",
      "Software Development\n",
      "The AI community building the future.\n",
      "See jobs\n",
      "Follow\n",
      "View all 640 employees\n",
      "Report this company\n",
      "About us\n",
      "The AI community building the future.\n",
      "Website\n",
      "https://huggingface.co\n",
      "External link for Hugging Face\n",
      "Industry\n",
      "Software Development\n",
      "Company size\n",
      "51-200 employees\n",
      "Type\n",
      "Privately Held\n",
      "Founded\n",
      "2016\n",
      "Specialties\n",
      "machine learning, natural language processing, and deep learning\n",
      "Products\n",
      "Hugging Face\n",
      "Hugging Face\n",
      "Natural Language Processing (NLP) Software\n",
      "We‚Äôre on a journey to solve and democratize artificial intelligence through natural language.\n",
      "Locations\n",
      "Primary\n",
      "Get directions\n",
      "Paris, FR\n",
      "Get directions\n",
      "Employees at Hugging Face\n",
      "Ludovic Huraux\n",
      "Rajat Arya\n",
      "Jeff Boudier\n",
      "Terrence Rohan\n",
      "See all employees\n",
      "Updates\n",
      "Hugging Face\n",
      "reposted this\n",
      "Julien Chaumond\n",
      "2d\n",
      "Report this post\n",
      "We got Claude Code to train an open LLM ü§Ø\n",
      "\n",
      "Not just to write the training script, but to actually submit jobs to cloud GPUs, monitor progress, and push finished models to the Hugging Face Hub. \n",
      "\n",
      "Just say something like: \"Fine-tune Qwen3-0.6B on the dataset open-r1/codeforces-cots\"\n",
      "\n",
      "This is using Skills: packaged instructions, scripts, and domain knowledge, to accomplish specialized tasks:\n",
      "\n",
      "- You tell the agent to fine-tune a model on a dataset. You can define the dataset or let it search.\n",
      "- Agent picks hardware based on model size and checks dataset.\n",
      "- Job runs on cloud gpus. Either main run, or test run.\n",
      "- Agent share real-time progress dashboard with Trackio.\n",
      "- Checkpoints are pushed to HF.\n",
      "\n",
      "Check out the full tutorial ‚§µÔ∏è\n",
      "8,343\n",
      "242 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Jeff Boudier\n",
      "4d\n",
      "Report this post\n",
      "Can you make Claude reduce your Claude costs?\n",
      "\n",
      "Just came back from AWS re:Invent ; heard from multiple companies they got success building their own agents but each call costs $3-$5, due to ballooning tokens and Claude costs.\n",
      "\n",
      "\n",
      "\n",
      "###social media - Twitter\n",
      "No title found\n",
      "\n",
      "JavaScript is not available.\n",
      "We‚Äôve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.\n",
      "Help Center\n",
      "Terms of Service\n",
      "Privacy Policy\n",
      "Cookie Policy\n",
      "Imprint\n",
      "Ads info\n",
      "¬© 2025 X Corp.\n",
      "Something went wrong, but don‚Äôt fret ‚Äî let‚Äôs give it another shot.\n",
      "Try again\n",
      "Some privacy related extensions may cause issues on x.com. Please disable them and try again.\n",
      "\n",
      "###GitHub page\n",
      "Hugging Face ¬∑ GitHub\n",
      "\n",
      "Skip to content\n",
      "Navigation Menu\n",
      "Toggle navigation\n",
      "Sign in\n",
      "Appearance settings\n",
      "huggingface\n",
      "Platform\n",
      "GitHub Copilot\n",
      "Write better code with AI\n",
      "GitHub Spark\n",
      "New\n",
      "Build and deploy intelligent apps\n",
      "GitHub Models\n",
      "New\n",
      "Manage and compare prompts\n",
      "GitHub Advanced Security\n",
      "Find and fix vulnerabilities\n",
      "Actions\n",
      "Automate any workflow\n",
      "Codespaces\n",
      "Instant dev environments\n",
      "Issues\n",
      "Plan and track work\n",
      "Code Review\n",
      "Manage code changes\n",
      "Discussions\n",
      "Collaborate outside of code\n",
      "Code Search\n",
      "Find more, search less\n",
      "Explore\n",
      "Why GitHub\n",
      "Documentation\n",
      "GitHub Skills\n",
      "Blog\n",
      "Integrations\n",
      "GitHub Marketplace\n",
      "MCP Registry\n",
      "View all features\n",
      "Solutions\n",
      "By company size\n",
      "Enterprises\n",
      "Small and medium teams\n",
      "Startups\n",
      "Nonprofits\n",
      "By use case\n",
      "App Modernization\n",
      "DevSecOps\n",
      "DevOps\n",
      "CI/CD\n",
      "View all use cases\n",
      "By industry\n",
      "Healthcare\n",
      "Financial services\n",
      "Manufacturing\n",
      "Government\n",
      "View all industries\n",
      "View all solutions\n",
      "Resources\n",
      "Topics\n",
      "AI\n",
      "DevOps\n",
      "Security\n",
      "Software Development\n",
      "View all\n",
      "Explore\n",
      "Learning Pathways\n",
      "Events & Webinars\n",
      "Ebooks & Whitepapers\n",
      "Customer Stories\n",
      "Partners\n",
      "Executive Insights\n",
      "Open Source\n",
      "GitHub Sponsors\n",
      "Fund open source developers\n",
      "The ReadME Project\n",
      "GitHub community articles\n",
      "Repositories\n",
      "Topics\n",
      "Trending\n",
      "Collections\n",
      "Enterprise\n",
      "Enterprise platform\n",
      "AI-powered developer platform\n",
      "Available add-ons\n",
      "GitHub Advanced Security\n",
      "Enterprise-grade security features\n",
      "Copilot for business\n",
      "Enterprise-grade AI features\n",
      "Premium Support\n",
      "Enterprise-grade 24/7 support\n",
      "Pricing\n",
      "Search or jump to...\n",
      "Search code, repositories, users, issues, pull requests...\n",
      "Search\n",
      "Clear\n",
      "Search syntax tips\n",
      "Provide feedback\n",
      "We read every piece of feedback, and take your input very seriously.\n",
      "Include my email address so I can be contacted\n",
      "Cancel\n",
      "Submit feedback\n",
      "Saved searches\n",
      "Use saved searches to filter your results more quickly\n",
      "Cancel\n",
      "Create saved search\n",
      "Sign in\n",
      "Sign up\n",
      "Appearance settings\n",
      "Resetting focus\n",
      "You signed in with another tab or window.\n",
      "Reload\n",
      "to refresh your session.\n",
      "You signed out in another tab or window.\n",
      "Reload\n",
      "to refresh yo\n"
     ]
    }
   ],
   "source": [
    "print(fetch_website_and_contents(\"https://huggingface.co/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5efa083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "broucher_gen_sys_prompt=\"\"\"You are an assistant that analyzes the contents of several relevant pages from a company website\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits.\n",
    "Respond in markdown without code blocks.\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0acb5f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_broucher_user_prompt(companyname, url):\n",
    "    user_prompt = f\"\"\"you are looking at a company called: {companyname}, here are the contents of its landing page and relevant pages; \n",
    "    use this information to generate a short broucher, give in a markdown without code blocks\"\"\"\n",
    "    user_prompt += fetch_website_and_contents(url)\n",
    "    user_prompt = user_prompt[:5_000]\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40ff853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_company_broucher(companyname, url, ai, model):\n",
    "    response = ai.chat.completions.create(\n",
    "        model= model,\n",
    "        messages = [{\"role\":\"system\", \"content\" : broucher_gen_sys_prompt},\n",
    "               {\"role\" : \"user\", \"content\" : get_broucher_user_prompt(companyname,url)}])\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f893402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hugging Face ‚Äî The AI community building the future\n",
       "\n",
       "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
       "\n",
       "Key value proposition\n",
       "- The Home of Machine Learning: create, discover, and collaborate on ML faster.\n",
       "- The collaboration platform: host and collaborate on unlimited public models, datasets, and applications.\n",
       "- Move faster with the HF Open source stack.\n",
       "- Explore all modalities: text, image, video, audio, or even 3D.\n",
       "- Build your portfolio: share your work with the world and grow your ML profile.\n",
       "- Sign Up to join the community, publish your work, and accelerate your ML journey.\n",
       "\n",
       "What we offer\n",
       "- A huge ecosystem: browse 1M+ models, plus Spaces and datasets.\n",
       "- Spaces: running applications and demos (examples include image generation from prompts, evaluation guides, video generation from images, and more).\n",
       "- Fully managed deployment: Inference Endpoints to productionize models with minimal setup.\n",
       "- One-click deployment: import models from Hugging Face or browse a hand-picked catalog.\n",
       "- Compatibility with leading AI stacks: vLLM, TGI, SGLang, TEI, and custom containers.\n",
       "- Seamless Hugging Face Hub integration: fast, secure model weight downloads.\n",
       "- Future-proof AI stack: stay current with the latest frameworks and optimizations without messy upgrades.\n",
       "- Pricing options: Self-Serve, pay-as-you-go, billed per minute for Inf¬≠erence Endpoints.\n",
       "\n",
       "Inference Endpoints ‚Äî produce at scale\n",
       "- Fully managed infrastructure: no Kubernetes or CUDA setup required.\n",
       "- Autoscaling: scales with traffic to optimize costs.\n",
       "- Observability: comprehensive logs and metrics to understand and debug models.\n",
       "- Flexible inference engines: choose from vLLM, TGI, SGLang, TEI, or custom containers.\n",
       "- Significantly easier production deployment: one-click imports from the catalog, fast deployment, and secure weights transfer.\n",
       "- Per-minute pricing: a transparent, usage-based model.\n",
       "\n",
       "Pricing\n",
       "- Self-Serve, pay-as-you-go model for Inference Endpoints.\n",
       "- Pay for what you use, per minute.\n",
       "\n",
       "Community, customers, and partners\n",
       "- Trusted by teams running AI models on Inference Endpoints (leading organizations deploy with our platform).\n",
       "- A thriving community of researchers, developers, and data scientists building together.\n",
       "- Enterprise and team offerings to equip organizations with the most advanced platform for AI deployment.\n",
       "\n",
       "Careers and culture\n",
       "- The AI community building the future ‚Äî that mission underpins who we are and how we work.\n",
       "- Founded in 2016; privately held with a growing team (collaborative culture, openness, and a focus on democratizing artificial intelligence).\n",
       "- Current openings available on our careers page; join a fast-growing team focused on machine learning, NLP, and deep learning.\n",
       "- LinkedIn presence highlights our size (hundreds of employees) and focus areas.\n",
       "\n",
       "Get involved\n",
       "- Sign up or log in to join the community, publish work, and access tools.\n",
       "- Browse the catalog of models, datasets, and applications.\n",
       "- Learn more about Inference Endpoints and Enterprise options.\n",
       "- Explore enterprise solutions designed for teams and organizations.\n",
       "\n",
       "Website navigation highlights\n",
       "- Models, Datasets, Spaces, Community, Docs, Enterprise, Pricing\n",
       "- Explore AI Apps or Browse 1M+ models\n",
       "- Inference Endpoints, Catalog, and a growing catalog of ready-to-deploy models\n",
       "- Pricing and plans for individual users to large teams\n",
       "\n",
       "If you‚Äôd like more details or a tailored overview for prospective investors or potential hires, I can tailor this brochure to emphasize specific aspects (technical capabilities, customer stories, or career paths) and include direct calls to action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_company_broucher(\"HuggingFace\", \"https://huggingface.co/\",get_ai_instance()[0],get_ai_instance()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "66e72fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url,ai, model):\n",
    "    stream = ai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": broucher_gen_sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_broucher_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce65bc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Hugging Face Brochure\n",
       "\n",
       "---\n",
       "\n",
       "## About Hugging Face\n",
       "\n",
       "**Hugging Face** is a vibrant AI community and technology company dedicated to building the future of machine learning. Founded in 2016, Hugging Face specializes in advancing machine learning, natural language processing (NLP), and deep learning through an open and collaborative platform. With a team of 51-200 passionate employees, the company is privately held and actively shaping the democratization of artificial intelligence.\n",
       "\n",
       "---\n",
       "\n",
       "## What We Offer\n",
       "\n",
       "### The Home of Machine Learning Collaboration  \n",
       "Hugging Face provides the ultimate platform where the global machine learning community can create, discover, and collaborate on a vast array of models, datasets, and applications. With over 1 million models and 250,000 datasets accessible, users accelerate ML research and development across multiple modalities including text, image, video, audio, and even 3D.\n",
       "\n",
       "### Key Features:\n",
       "- **Public Hosting & Collaboration:** Host unlimited public models, datasets, and applications.\n",
       "- **Wide Variety of Modalities:** Support for text generation, image generation, video synthesis, and more.\n",
       "- **Machine Learning Applications:** Over 400,000 AI apps available to explore and build upon.\n",
       "- **Open Source Stack:** Move faster with Hugging Face‚Äôs open-source tools and libraries.\n",
       "- **Portfolio Building:** Share your work globally and build your professional ML profile.\n",
       "\n",
       "### Enterprise & Compute Solutions  \n",
       "For organizations and teams seeking to scale AI deployment, Hugging Face offers paid compute resources and enterprise-grade solutions. Their **Inference Endpoints** service allows seamless, one-click deployment of AI models on a fully managed platform with autoscaling, observability, and robust infrastructure‚Äîeliminating the hassles of backend configuration.\n",
       "\n",
       "---\n",
       "\n",
       "## Customers and Community\n",
       "\n",
       "Hugging Face is trusted by industry-leading teams who deploy AI models on their managed inference platform. The community includes researchers, developers, startups, and enterprises, all collaborating through a shared platform to push the boundaries of AI innovation.\n",
       "\n",
       "---\n",
       "\n",
       "## Company Culture\n",
       "\n",
       "Hugging Face fosters a culture of openness, collaboration, and continuous learning. They emphasize:\n",
       "- Building **inclusive AI communities** where knowledge is freely shared.\n",
       "- Encouraging **creativity and experimentation** in machine learning projects.\n",
       "- Supporting contributors and users at all skill levels to build meaningful AI applications.\n",
       "- Prioritizing transparent and **open source development** to democratize AI.\n",
       "\n",
       "---\n",
       "\n",
       "## Careers at Hugging Face\n",
       "\n",
       "Are you passionate about AI and eager to work in a fast-growing, innovative environment? Hugging Face offers exciting career opportunities in software development, research, and AI engineering. Join a dedicated team that is shaping the future of machine learning and contributing actively to global AI advancement.\n",
       "\n",
       "Explore current job openings and apply to become part of the AI community building the future.\n",
       "\n",
       "---\n",
       "\n",
       "## Connect With Us\n",
       "\n",
       "- Website: [huggingface.co](https://huggingface.co)  \n",
       "- LinkedIn: [Hugging Face on LinkedIn](https://www.linkedin.com/company/huggingface)  \n",
       "- Join the community, collaborate on models, and start building your AI applications today!\n",
       "\n",
       "---\n",
       "\n",
       "**Hugging Face** ‚Äì Empowering the AI community to build the future of machine learning."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co/\",get_ai_instance()[0],\"gpt-4.1-mini\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
